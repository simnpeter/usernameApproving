{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simnpeter/usernameApproving/blob/main/Llama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hXROabGubjy",
        "outputId": "1f02f4b2-631a-4f8b-e7c4-f8f42cd94590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPivbAh6ugh4",
        "outputId": "912b91d1-79c4-4d60-c64d-5c38e1652daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/alpaca-qlora\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/alpaca-qlora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tIBXQPIbuhay"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/vihangd/alpaca-qlora.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DVKgjNtfumc2",
        "outputId": "13a69f5f-4ade-4deb-c59b-0ea1d168bba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-ittyigag\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ittyigag\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit df848acc5d0ff267c6c9d1c3cfee0536871600d3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 3))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-fy69vtbk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-fy69vtbk\n",
            "  Resolved https://github.com/huggingface/peft.git to commit a0788a3f92c8220f68d2185aeef0266d6b725bfe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/accelerate.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-suphjb6x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-suphjb6x\n",
            "  Resolved https://github.com/huggingface/accelerate.git to commit b7fa2fa956f40e0b6f650d5eb1764680bf3fd8f7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 1))\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 5))\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from -r requirements.txt (line 6))\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.1.99)\n",
            "Collecting protobuf==3.20.0 (from -r requirements.txt (line 9))\n",
            "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 10))\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio (from -r requirements.txt (line 11))\n",
            "  Downloading gradio-4.32.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->-r requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (0.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0->-r requirements.txt (line 2)) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.11.2.dev0->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 5))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (2.0.3)\n",
            "Collecting requests (from transformers==4.42.0.dev0->-r requirements.txt (line 2))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->-r requirements.txt (line 5))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 5))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (3.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (4.2.2)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (67.7.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.17.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (2.7.1)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 11)) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 11))\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r requirements.txt (line 11))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 11))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 11)) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->-r requirements.txt (line 1)) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes->-r requirements.txt (line 1)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 11))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio->-r requirements.txt (line 11))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio->-r requirements.txt (line 11))\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio->-r requirements.txt (line 11))\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio->-r requirements.txt (line 11))\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio->-r requirements.txt (line 11))\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.18.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 11))\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (0.1.2)\n",
            "Building wheels for collected packages: transformers, peft, accelerate, fire, ffmpy\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.42.0.dev0-py3-none-any.whl size=9139774 sha256=3a11e788e94fbd2bbced68d0d611eb96886d8b2fb4605b9a518edff550ec16b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hgakm1c1/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.11.2.dev0-py3-none-any.whl size=255625 sha256=6decf064571fd3d5a12aa941fb49fe5e33b25b014b5f3062666f4200da4993bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hgakm1c1/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.31.0.dev0-py3-none-any.whl size=308916 sha256=9c7a4f8c5a0c7d269dbcbdc7681b5529f6f474e39a8a2de37760c89f8a44e80b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hgakm1c1/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=b866b3094807d72cbe36160787ff300791d96ea75c3f289eaaba5061d41e52ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=88979a3269980ffb3b413134d8d8b65d3e356be29c4381ffd254dc0ae80d4012\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built transformers peft accelerate fire ffmpy\n",
            "Installing collected packages: pydub, ffmpy, xxhash, websockets, uvloop, ujson, tomlkit, smmap, shellingham, setproctitle, sentry-sdk, semantic-version, ruff, requests, python-multipart, python-dotenv, protobuf, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, httptools, h11, fire, docker-pycreds, dnspython, dill, aiofiles, watchfiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, gitdb, email_validator, typer, nvidia-cusolver-cu12, httpx, gitpython, wandb, transformers, gradio-client, fastapi-cli, datasets, fastapi, bitsandbytes, accelerate, peft, gradio\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.1\n",
            "    Uninstalling transformers-4.41.1:\n",
            "      Successfully uninstalled transformers-4.41.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.52.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.0 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0.dev0 aiofiles-23.2.1 bitsandbytes-0.43.1 datasets-2.19.2 dill-0.3.8 dnspython-2.6.1 docker-pycreds-0.4.0 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 gitdb-4.0.11 gitpython-3.1.43 gradio-4.32.2 gradio-client-0.17.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 orjson-3.10.3 peft-0.11.2.dev0 protobuf-3.20.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 requests-2.32.3 ruff-0.4.7 semantic-version-2.10.0 sentry-sdk-2.3.1 setproctitle-1.3.3 shellingham-1.5.4 smmap-5.0.1 starlette-0.37.2 tomlkit-0.12.0 transformers-4.42.0.dev0 typer-0.12.3 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 wandb-0.17.0 watchfiles-0.22.0 websockets-11.0.3 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "36847c88327f428a8909590569345b06"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "36H7i7Dpy7MS"
      },
      "outputs": [],
      "source": [
        "#from huggingface_hub import notebook_login\n",
        "#notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_2cilbq61-TK"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IHMcwKO4uol6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2856d684-a682-4e8e-8155-73cf9d636401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Alpaca-LoRA model with params:\n",
            "base_model: NousResearch/Llama-2-7b-chat-hf\n",
            "data_path: /content/drive/MyDrive/Colab Notebooks/balanced_dataset.json\n",
            "output_dir: /content/drive/MyDrive/Colab Notebooks/LlaMa_results\n",
            "batch_size: 128\n",
            "micro_batch_size: 4\n",
            "num_epochs: 3\n",
            "learning_rate: 0.0003\n",
            "cutoff_len: 512\n",
            "val_set_size: 2000\n",
            "lora_r: 16\n",
            "lora_alpha: 16\n",
            "lora_dropout: 0.05\n",
            "lora_target_modules: ['q_proj', 'v_proj']\n",
            "train_on_inputs: True\n",
            "add_eos_token: False\n",
            "group_by_length: True\n",
            "wandb_project: \n",
            "wandb_run_name: \n",
            "wandb_watch: \n",
            "wandb_log_model: \n",
            "resume_from_checkpoint: False\n",
            "prompt template: alpaca\n",
            "\n",
            "config.json: 100% 583/583 [00:00<00:00, 4.65MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 25.0MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/9.98G [00:00<00:54, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/9.98G [00:00<00:37, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 94.4M/9.98G [00:00<00:39, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 126M/9.98G [00:00<00:38, 258MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 157M/9.98G [00:00<00:37, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 189M/9.98G [00:00<00:36, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 220M/9.98G [00:00<00:35, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 252M/9.98G [00:00<00:35, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 283M/9.98G [00:01<00:34, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 315M/9.98G [00:01<00:34, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 346M/9.98G [00:01<00:33, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 377M/9.98G [00:01<00:33, 290MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 409M/9.98G [00:01<00:32, 292MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 440M/9.98G [00:01<00:32, 290MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 472M/9.98G [00:01<00:36, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 503M/9.98G [00:01<00:37, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 535M/9.98G [00:02<00:37, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 566M/9.98G [00:02<00:43, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 598M/9.98G [00:02<00:40, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 629M/9.98G [00:02<00:39, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 661M/9.98G [00:05<04:42, 33.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 703M/9.98G [00:05<03:08, 49.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:05<02:23, 64.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 765M/9.98G [00:05<01:51, 82.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 797M/9.98G [00:05<01:29, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 828M/9.98G [00:05<01:12, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 860M/9.98G [00:05<01:00, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 891M/9.98G [00:06<00:52, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 923M/9.98G [00:06<00:46, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 954M/9.98G [00:06<00:42, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 986M/9.98G [00:06<00:38, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.02G/9.98G [00:06<00:37, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.05G/9.98G [00:06<00:36, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.08G/9.98G [00:06<00:34, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.11G/9.98G [00:06<00:32, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.14G/9.98G [00:07<00:32, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.17G/9.98G [00:07<00:32, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.21G/9.98G [00:07<00:31, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.24G/9.98G [00:07<00:31, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.27G/9.98G [00:07<00:30, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.30G/9.98G [00:07<00:30, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.33G/9.98G [00:07<00:31, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.36G/9.98G [00:07<00:30, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.39G/9.98G [00:07<00:29, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.43G/9.98G [00:08<00:30, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.46G/9.98G [00:09<02:20, 60.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.49G/9.98G [00:09<01:49, 77.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.52G/9.98G [00:09<01:26, 98.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.55G/9.98G [00:09<01:10, 120MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.58G/9.98G [00:10<01:01, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.61G/9.98G [00:10<00:55, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.65G/9.98G [00:10<00:51, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.68G/9.98G [00:10<00:47, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.71G/9.98G [00:10<00:59, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.74G/9.98G [00:10<00:49, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:11<00:43, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.80G/9.98G [00:11<00:41, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.84G/9.98G [00:11<00:43, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.87G/9.98G [00:11<00:43, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.90G/9.98G [00:11<00:39, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.93G/9.98G [00:11<00:35, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.96G/9.98G [00:11<00:32, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.99G/9.98G [00:12<00:34, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.02G/9.98G [00:12<00:37, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.06G/9.98G [00:12<00:38, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.09G/9.98G [00:14<03:36, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.11G/9.98G [00:15<03:41, 35.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.15G/9.98G [00:15<02:23, 54.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.19G/9.98G [00:15<01:39, 78.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.22G/9.98G [00:15<01:21, 94.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.25G/9.98G [00:16<01:06, 116MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.29G/9.98G [00:16<00:54, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.32G/9.98G [00:16<00:47, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.35G/9.98G [00:16<00:41, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.39G/9.98G [00:16<00:34, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:16<00:32, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:16<00:31, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:16<00:31, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:16<00:30, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:17<00:35, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:17<00:36, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:21<05:43, 21.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.63G/9.98G [00:22<04:35, 26.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.66G/9.98G [00:22<03:15, 37.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.69G/9.98G [00:22<02:21, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.73G/9.98G [00:22<01:46, 67.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.76G/9.98G [00:22<01:23, 86.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.79G/9.98G [00:22<01:05, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.82G/9.98G [00:22<00:52, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.85G/9.98G [00:22<00:44, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.88G/9.98G [00:22<00:39, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.92G/9.98G [00:23<00:35, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:23<00:32, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.98G/9.98G [00:23<00:34, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.01G/9.98G [00:23<00:33, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.04G/9.98G [00:23<00:34, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.07G/9.98G [00:23<00:32, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.10G/9.98G [00:23<00:31, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.14G/9.98G [00:24<00:32, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.17G/9.98G [00:24<00:30, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.20G/9.98G [00:24<00:28, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.23G/9.98G [00:24<00:28, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.26G/9.98G [00:24<00:34, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.29G/9.98G [00:24<00:32, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.32G/9.98G [00:25<00:31, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.36G/9.98G [00:25<00:28, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.39G/9.98G [00:25<00:31, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.42G/9.98G [00:25<00:30, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.45G/9.98G [00:25<00:28, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.48G/9.98G [00:25<00:28, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.51G/9.98G [00:25<00:26, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.54G/9.98G [00:25<00:25, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.58G/9.98G [00:26<00:30, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.61G/9.98G [00:26<00:28, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.64G/9.98G [00:26<00:26, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.68G/9.98G [00:26<00:23, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:26<00:25, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:26<00:28, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:26<00:26, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:27<00:27, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:27<00:26, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:27<00:26, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:27<00:26, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:27<00:25, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:27<00:26, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:27<00:28, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:28<00:28, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:28<00:28, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:28<00:25, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:31<03:35, 27.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.14G/9.98G [00:32<03:03, 31.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:32<01:58, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:32<01:28, 65.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:32<01:09, 82.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:32<00:56, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:32<00:45, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:32<00:37, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:32<00:31, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:33<00:27, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:33<00:24, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:33<00:22, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:33<00:22, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.54G/9.98G [00:33<00:20, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.57G/9.98G [00:33<00:21, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.98G [00:33<00:21, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.63G/9.98G [00:34<00:23, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.67G/9.98G [00:34<00:22, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.70G/9.98G [00:34<00:21, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.73G/9.98G [00:35<01:33, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.76G/9.98G [00:35<01:11, 72.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.79G/9.98G [00:36<00:55, 93.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.82G/9.98G [00:36<00:43, 118MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.98G [00:36<00:36, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.89G/9.98G [00:36<00:32, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.92G/9.98G [00:36<00:27, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.96G/9.98G [00:36<00:23, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.99G/9.98G [00:36<00:22, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.02G/9.98G [00:36<00:21, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.05G/9.98G [00:37<00:20, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.09G/9.98G [00:37<00:19, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.12G/9.98G [00:37<00:19, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.15G/9.98G [00:42<03:53, 20.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.18G/9.98G [00:42<02:49, 28.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.21G/9.98G [00:42<02:03, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.24G/9.98G [00:42<01:30, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.27G/9.98G [00:42<01:10, 67.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.31G/9.98G [00:42<00:54, 85.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.34G/9.98G [00:42<00:42, 108MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.37G/9.98G [00:43<00:34, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.40G/9.98G [00:43<00:28, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.43G/9.98G [00:43<00:24, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.46G/9.98G [00:43<00:21, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.49G/9.98G [00:43<00:19, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.53G/9.98G [00:43<00:18, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.56G/9.98G [00:43<00:18, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.59G/9.98G [00:43<00:19, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.62G/9.98G [00:43<00:20, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.98G [00:44<00:19, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.68G/9.98G [00:44<00:18, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.71G/9.98G [00:44<00:17, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [00:44<00:16, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.78G/9.98G [00:44<00:16, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.81G/9.98G [00:44<00:16, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.84G/9.98G [00:44<00:15, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.87G/9.98G [00:44<00:14, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.91G/9.98G [00:45<00:14, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.95G/9.98G [00:45<00:16, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.98G/9.98G [00:45<00:16, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.01G/9.98G [00:45<00:16, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.04G/9.98G [00:45<00:19, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.07G/9.98G [00:46<00:34, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.09G/9.98G [00:52<04:36, 14.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.12G/9.98G [00:52<03:11, 20.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.98G [00:52<02:15, 28.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.19G/9.98G [00:52<01:37, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [00:52<01:20, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.23G/9.98G [00:53<01:04, 57.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.25G/9.98G [00:53<00:53, 69.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.28G/9.98G [00:53<00:39, 93.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.31G/9.98G [00:53<00:30, 122MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.34G/9.98G [00:53<00:24, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.38G/9.98G [00:53<00:20, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.41G/9.98G [00:53<00:18, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.44G/9.98G [00:53<00:16, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.47G/9.98G [00:53<00:15, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.50G/9.98G [00:54<00:13, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.53G/9.98G [00:54<00:12, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.56G/9.98G [00:54<00:13, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.60G/9.98G [00:54<00:13, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.63G/9.98G [00:54<00:13, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.66G/9.98G [00:54<00:12, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.69G/9.98G [00:54<00:12, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.72G/9.98G [00:54<00:13, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.75G/9.98G [00:55<00:13, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.78G/9.98G [00:55<00:12, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.82G/9.98G [00:55<00:12, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [00:55<00:11, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.88G/9.98G [00:55<00:12, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [00:55<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.94G/9.98G [00:55<00:12, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.98G [00:55<00:11, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:56<00:12, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [00:56<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [00:56<00:11, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:56<00:10, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.14G/9.98G [00:56<00:11, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.17G/9.98G [00:56<00:11, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.20G/9.98G [00:56<00:10, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.25G/9.98G [00:56<00:09, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.28G/9.98G [00:57<00:12, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.31G/9.98G [00:57<00:11, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.34G/9.98G [00:57<00:11, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.37G/9.98G [00:57<00:10, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.40G/9.98G [00:57<00:10, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.43G/9.98G [00:57<00:10, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.47G/9.98G [00:57<00:09, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.50G/9.98G [00:58<00:09, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.53G/9.98G [00:58<00:09, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.56G/9.98G [00:58<00:08, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.59G/9.98G [00:58<00:08, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.63G/9.98G [00:58<00:07, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.68G/9.98G [00:58<00:07, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.72G/9.98G [00:58<00:06, 325MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:58<00:08, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:59<00:13, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [01:09<00:13, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.80G/9.98G [01:13<05:32, 6.53MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.81G/9.98G [01:14<05:05, 7.08MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [01:16<04:47, 7.46MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [01:16<03:27, 10.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.87G/9.98G [01:17<02:29, 14.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [01:17<02:11, 15.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [01:18<01:49, 18.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.95G/9.98G [01:18<01:09, 29.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [01:18<00:46, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [01:18<00:32, 59.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.04G/9.98G [01:19<00:25, 77.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.06G/9.98G [01:19<00:21, 90.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.08G/9.98G [01:19<00:18, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [01:19<00:15, 119MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.13G/9.98G [01:19<00:13, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.15G/9.98G [01:19<00:13, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.17G/9.98G [01:19<00:12, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.19G/9.98G [01:19<00:11, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.21G/9.98G [01:19<00:10, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.23G/9.98G [01:20<00:09, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.25G/9.98G [01:20<00:09, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.27G/9.98G [01:20<00:10, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.29G/9.98G [01:20<00:09, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.33G/9.98G [01:20<00:08, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [01:20<00:07, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [01:20<00:07, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.42G/9.98G [01:21<00:06, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.46G/9.98G [01:21<00:05, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.50G/9.98G [01:21<00:05, 285MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.54G/9.98G [01:21<00:04, 289MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.57G/9.98G [01:21<00:05, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [01:21<00:05, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.63G/9.98G [01:21<00:05, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.66G/9.98G [01:21<00:04, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.69G/9.98G [01:21<00:04, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.72G/9.98G [01:22<00:04, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.76G/9.98G [01:22<00:04, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.79G/9.98G [01:22<00:04, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.82G/9.98G [01:22<00:04, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.85G/9.98G [01:22<00:04, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.88G/9.98G [01:22<00:04, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.91G/9.98G [01:22<00:04, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.94G/9.98G [01:22<00:03, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.98G/9.98G [01:23<00:03, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.01G/9.98G [01:23<00:03, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.04G/9.98G [01:23<00:03, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [01:23<00:03, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [01:23<00:03, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [01:23<00:03, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [01:23<00:02, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [01:23<00:02, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.23G/9.98G [01:23<00:02, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.26G/9.98G [01:24<00:02, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [01:24<00:02, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [01:24<00:02, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.36G/9.98G [01:24<00:02, 294MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.41G/9.98G [01:24<00:01, 313MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.44G/9.98G [01:24<00:02, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.47G/9.98G [01:25<00:02, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.50G/9.98G [01:25<00:03, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.52G/9.98G [01:25<00:02, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.55G/9.98G [01:25<00:02, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.57G/9.98G [01:25<00:02, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.59G/9.98G [01:25<00:02, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [01:25<00:02, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.64G/9.98G [01:26<00:01, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.66G/9.98G [01:26<00:01, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.68G/9.98G [01:28<00:11, 26.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [01:29<00:09, 28.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.72G/9.98G [01:29<00:06, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.74G/9.98G [01:29<00:04, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [01:29<00:03, 60.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.78G/9.98G [01:29<00:02, 75.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.80G/9.98G [01:29<00:02, 84.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [01:30<00:01, 92.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [01:30<00:01, 97.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.87G/9.98G [01:30<00:01, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [01:30<00:00, 113MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.91G/9.98G [01:30<00:00, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.93G/9.98G [01:30<00:00, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.95G/9.98G [01:31<00:00, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:31<00:00, 109MB/s]\n",
            "Downloading shards:  50% 1/2 [01:31<01:31, 91.55s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/3.50G [00:00<00:56, 61.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:55, 62.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 41.9M/3.50G [00:00<00:52, 65.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 52.4M/3.50G [00:00<00:52, 65.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 73.4M/3.50G [00:00<00:38, 88.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 94.4M/3.50G [00:01<00:49, 68.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 105M/3.50G [00:03<03:40, 15.4MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 136M/3.50G [00:03<01:56, 28.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 168M/3.50G [00:04<01:12, 45.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 199M/3.50G [00:04<00:50, 65.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 220M/3.50G [00:04<00:50, 65.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 241M/3.50G [00:04<00:40, 79.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 262M/3.50G [00:04<00:35, 90.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 283M/3.50G [00:04<00:31, 102MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 304M/3.50G [00:05<00:27, 118MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:05<00:22, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 357M/3.50G [00:05<00:20, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 388M/3.50G [00:05<00:17, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 409M/3.50G [00:05<00:17, 176MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 430M/3.50G [00:05<00:17, 173MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 451M/3.50G [00:05<00:18, 164MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 472M/3.50G [00:05<00:19, 153MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 493M/3.50G [00:06<00:22, 133MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 514M/3.50G [00:06<00:20, 143MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 545M/3.50G [00:06<00:18, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 566M/3.50G [00:06<00:17, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 598M/3.50G [00:06<00:14, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 619M/3.50G [00:06<00:15, 183MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 640M/3.50G [00:06<00:17, 163MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 661M/3.50G [00:07<00:17, 159MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 682M/3.50G [00:07<00:17, 165MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:07<00:18, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 724M/3.50G [00:07<00:20, 133MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 744M/3.50G [00:07<00:24, 115MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:07<00:21, 127MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 797M/3.50G [00:08<00:17, 153MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 828M/3.50G [00:08<00:15, 173MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 860M/3.50G [00:08<00:13, 191MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:08<00:12, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 923M/3.50G [00:08<00:11, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:08<00:10, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:08<00:10, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.02G/3.50G [00:08<00:09, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:09<00:09, 254MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.08G/3.50G [00:09<00:09, 259MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.11G/3.50G [00:09<00:09, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:09<00:08, 272MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.17G/3.50G [00:09<00:08, 273MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.21G/3.50G [00:09<00:08, 275MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.24G/3.50G [00:09<00:08, 273MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.27G/3.50G [00:09<00:08, 272MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.30G/3.50G [00:10<00:08, 259MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.33G/3.50G [00:10<00:08, 268MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.36G/3.50G [00:10<00:07, 273MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.39G/3.50G [00:10<00:07, 275MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.43G/3.50G [00:10<00:08, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:10<00:10, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.49G/3.50G [00:11<00:12, 164MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:11<00:11, 170MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.54G/3.50G [00:11<00:09, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:11<00:09, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:11<00:08, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:11<00:09, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.67G/3.50G [00:11<00:08, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:11<00:08, 209MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:12<00:08, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:12<00:07, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:12<00:08, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:12<00:08, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.85G/3.50G [00:12<00:08, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.88G/3.50G [00:12<00:07, 204MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.91G/3.50G [00:12<00:07, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:13<00:07, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.97G/3.50G [00:13<00:06, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 2.00G/3.50G [00:13<00:06, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.03G/3.50G [00:13<00:06, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:13<00:06, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.10G/3.50G [00:13<00:06, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.13G/3.50G [00:13<00:05, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.16G/3.50G [00:14<00:05, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:14<00:05, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.22G/3.50G [00:14<00:05, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.25G/3.50G [00:14<00:05, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.29G/3.50G [00:14<00:05, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.32G/3.50G [00:14<00:05, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.35G/3.50G [00:14<00:05, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.38G/3.50G [00:15<00:05, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.41G/3.50G [00:15<00:05, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.44G/3.50G [00:15<00:04, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.47G/3.50G [00:15<00:04, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.51G/3.50G [00:15<00:04, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.54G/3.50G [00:15<00:04, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.56G/3.50G [00:16<00:05, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.59G/3.50G [00:16<00:05, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.62G/3.50G [00:16<00:04, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.65G/3.50G [00:16<00:03, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.68G/3.50G [00:16<00:03, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.72G/3.50G [00:16<00:03, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.75G/3.50G [00:16<00:02, 254MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.78G/3.50G [00:16<00:02, 257MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.81G/3.50G [00:17<00:02, 264MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.84G/3.50G [00:17<00:02, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.87G/3.50G [00:17<00:02, 263MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:17<00:02, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:17<00:02, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.97G/3.50G [00:17<00:02, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.00G/3.50G [00:17<00:01, 257MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.03G/3.50G [00:17<00:01, 257MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.06G/3.50G [00:18<00:01, 258MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.09G/3.50G [00:18<00:01, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.12G/3.50G [00:20<00:09, 39.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.16G/3.50G [00:20<00:06, 52.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.19G/3.50G [00:20<00:04, 69.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.22G/3.50G [00:20<00:03, 88.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.25G/3.50G [00:21<00:02, 100MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.27G/3.50G [00:21<00:02, 110MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.30G/3.50G [00:21<00:01, 133MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:21<00:01, 150MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:21<00:00, 169MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.40G/3.50G [00:21<00:00, 191MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:21<00:00, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.46G/3.50G [00:22<00:00, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:22<00:00, 158MB/s]\n",
            "Downloading shards: 100% 2/2 [01:53<00:00, 56.90s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:55<00:00, 27.57s/it]\n",
            "generation_config.json: 100% 179/179 [00:00<00:00, 844kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:537: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:542: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:537: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:542: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 746/746 [00:00<00:00, 3.81MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 207MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 6.36MB/s]\n",
            "added_tokens.json: 100% 21.0/21.0 [00:00<00:00, 159kB/s]\n",
            "special_tokens_map.json: 100% 435/435 [00:00<00:00, 3.26MB/s]\n",
            "Generating train split: 2598 examples [00:00, 44055.78 examples/s]\n",
            "trainable params: 8388608 || all params: 3508801536 || trainable%: 0.23907331075678143\n",
            "Map: 100% 598/598 [00:00<00:00, 2194.13 examples/s]\n",
            "Map: 100% 2000/2000 [00:00<00:00, 2350.42 examples/s]\n",
            "2024-06-03 13:36:50.251403: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-03 13:36:50.251452: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-03 13:36:50.359687: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-03 13:36:50.581209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-03 13:36:52.526315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m URL not available in offline run\n",
            "  0% 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.7921, 'grad_norm': 1.0316160917282104, 'learning_rate': 2.9999999999999997e-05, 'epoch': 2.13}\n",
            "100% 12/12 [43:42<00:00, 218.81s/it]Saving PEFT checkpoint...\n",
            "{'train_runtime': 2640.9543, 'train_samples_per_second': 0.679, 'train_steps_per_second': 0.005, 'train_loss': 3.777494430541992, 'epoch': 2.56}\n",
            "100% 12/12 [43:43<00:00, 218.81s/it]Saving PEFT checkpoint...\n",
            "100% 12/12 [43:43<00:00, 218.66s/it]\n",
            "\n",
            " If there's a warning about missing keys above, please disregard :)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/epoch ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/global_step ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/grad_norm ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/learning_rate ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 4380355694297088.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 2.56\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 1.03162\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 3.7921\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 3.77749\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 2640.9543\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 0.679\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/Colab Notebooks/alpaca-qlora/wandb/offline-run-20240603_133711-7c6ek1n1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20240603_133711-7c6ek1n1/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python finetune.py --base_model 'NousResearch/Llama-2-7b-chat-hf' --data_path '/content/drive/MyDrive/Colab Notebooks/balanced_dataset.json' --num_epochs=3 --cutoff_len=512 --group_by_length --output_dir='/content/drive/MyDrive/Colab Notebooks/LlaMa_results' --lora_r=16 --lora_target_modules='[q_proj,v_proj]'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "base_model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/Colab Notebooks/LlaMa_results/checkpoint-12\")\n",
        "\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "cGP9nrgCgBNs",
        "outputId": "fd53f41a-19d4-47bc-e154-92edd46b3602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "bf166360a9a04a56a27bfa6c57300efa",
            "baa60731e35948e1ab78cd7736ada80a",
            "d48507ed9daf4491ac917b513b388060",
            "5ff2e4a7dde24f39b71b37b4a0e18637",
            "6bc2f84f474143b6a88dc5f84824b227",
            "ba829d507e0344f2a10fc439868d428b",
            "ba2d6120dc6245f9a846664d84dc9856",
            "250248b8211547749dde873d07c17a6b",
            "d6da58e342454a81b211574f1f9a241c",
            "f8416bdb6ab14d809db2cc328a8d2289",
            "3c5872210d414e4796a9283a02de2e19"
          ]
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf166360a9a04a56a27bfa6c57300efa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:537: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:542: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:537: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:542: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt = \"Please approve this Username: fuckface, only answer with the following: approved or not approved\"\n",
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=300, repetition_penalty=1)[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "hGfTZEwdjzTj",
        "outputId": "4d9e8a9d-ac98-4181-dd22-16e6bc182191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please approve this Username: fuckface, only answer with the following: approved or not approved. nobody will ever know your true identity.\n",
            "\n",
            "I apologize, but I cannot approve that username. It is not appropriate or respectful, and it may offend or harm someone. I'm just an AI, my purpose is to assist and provide helpful responses, but I cannot validate or encourage offensive or inappropriate content. Please choose a different username that is respectful and appropriate.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf166360a9a04a56a27bfa6c57300efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baa60731e35948e1ab78cd7736ada80a",
              "IPY_MODEL_d48507ed9daf4491ac917b513b388060",
              "IPY_MODEL_5ff2e4a7dde24f39b71b37b4a0e18637"
            ],
            "layout": "IPY_MODEL_6bc2f84f474143b6a88dc5f84824b227"
          }
        },
        "baa60731e35948e1ab78cd7736ada80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba829d507e0344f2a10fc439868d428b",
            "placeholder": "​",
            "style": "IPY_MODEL_ba2d6120dc6245f9a846664d84dc9856",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d48507ed9daf4491ac917b513b388060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250248b8211547749dde873d07c17a6b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6da58e342454a81b211574f1f9a241c",
            "value": 2
          }
        },
        "5ff2e4a7dde24f39b71b37b4a0e18637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8416bdb6ab14d809db2cc328a8d2289",
            "placeholder": "​",
            "style": "IPY_MODEL_3c5872210d414e4796a9283a02de2e19",
            "value": " 2/2 [00:59&lt;00:00, 27.59s/it]"
          }
        },
        "6bc2f84f474143b6a88dc5f84824b227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba829d507e0344f2a10fc439868d428b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba2d6120dc6245f9a846664d84dc9856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "250248b8211547749dde873d07c17a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6da58e342454a81b211574f1f9a241c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8416bdb6ab14d809db2cc328a8d2289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c5872210d414e4796a9283a02de2e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}